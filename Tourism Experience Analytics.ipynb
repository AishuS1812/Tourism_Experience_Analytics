{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AioLhmXjTYQo",
        "outputId": "7d4b6145-c564-4b3c-d294-b17ce3b877dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (3.0.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: surprise in /usr/local/lib/python3.11/dist-packages (0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (from surprise) (1.1.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.40.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy scikit-learn seaborn matplotlib xgboost lightgbm streamlit surprise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Set Up Your Environment\n"
      ],
      "metadata": {
        "id": "TZJ3dhCvUSqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file and print sheet names\n",
        "file_path = \"/content/Tourism Dataset (1).xlsx\"\n",
        "xls = pd.ExcelFile(file_path)\n",
        "print(\"Available Sheets:\", xls.sheet_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VfbVKHjVK9i",
        "outputId": "06e8fd76-33cc-48db-fc0b-61cf347862f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Sheets: ['User', 'Type', 'Transaction', 'Region', 'Mode ', 'Item', 'Country', 'Continent', 'City']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Merge transaction, user, item, city, type, continent\n",
        "d = transaction.merge(user, on=\"UserId\", how=\"left\") \\\n",
        "                .merge(item, on=\"AttractionId\", how=\"left\") \\\n",
        "                .merge(city, left_on=\"AttractionCityId\", right_on=\"CityId\", how=\"left\", suffixes=('', '_City')) \\\n",
        "                .merge(type_df, on=\"AttractionTypeId\", how=\"left\") \\\n",
        "                .merge(continent, on=\"ContinentId\", how=\"left\")\n",
        "\n",
        "# Step 2: Merge country and preserve RegionId safely\n",
        "country = country.rename(columns={\"RegionId\": \"CountryRegionId\"})  # avoid conflict\n",
        "d = d.merge(country, on=\"CountryId\", how=\"left\")\n",
        "\n",
        "# Step 3: Merge region using the renamed key\n",
        "region = region.rename(columns={\"RegionId\": \"CountryRegionId\"})  # match with above\n",
        "d = d.merge(region, on=\"CountryRegionId\", how=\"left\")\n",
        "\n",
        "# Final cleaning\n",
        "d.dropna(inplace=True)\n",
        "\n",
        "# Show structure\n",
        "print(\"‚úÖ Final Merged DataFrame Shape:\", df.shape)\n",
        "print(d.columns.tolist())\n",
        "print(d.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "ihKMkgK3ZLcl",
        "outputId": "3c958f50-90f7-48ef-c2b3-e45c223b544d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'transaction' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-211e09a8a362>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 1: Merge transaction, user, item, city, type, continent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransaction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"UserId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AttractionId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AttractionCityId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CityId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_City'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AttractionTypeId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'transaction' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file and print sheet names\n",
        "file_path = \"tf.xlsx\"\n",
        "xls = pd.ExcelFile(file_path)\n",
        "print(\"Available Sheets:\", xls.sheet_names)\n",
        "\n",
        "# Load data from each sheet into a DataFrame\n",
        "try:\n",
        "    transaction = xls.parse('transaction') # Assuming a sheet named 'transaction'\n",
        "    user = xls.parse('user')             # Assuming a sheet named 'user'\n",
        "    item = xls.parse('item')             # Assuming a sheet named 'item'\n",
        "    city = xls.parse('city')             # Assuming a sheet named 'city'\n",
        "    # Adjust the sheet name based on the actual name in your Excel file\n",
        "    type_df = xls.parse('type')          # Assuming a sheet named 'type' or similar\n",
        "    continent = xls.parse('continent')   # Assuming a sheet named 'continent'\n",
        "    country = xls.parse('country')       # Assuming a sheet named 'country'\n",
        "    region = xls.parse('region')         # Assuming a sheet named 'region'\n",
        "\n",
        "    print(\"‚úÖ DataFrames loaded from Excel sheets.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading data from Excel sheets: {e}\")\n",
        "    print(\"Please ensure the sheet names in 'tf.xlsx' match the code.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsssnGzwtVpr",
        "outputId": "ec68d1d4-2795-419d-a050-9a5f3f6017b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Sheets: ['User', 'Type', 'Transaction', 'Region', 'Mode ', 'Item', 'Country', 'Continent', 'City']\n",
            "‚ùå Error loading data from Excel sheets: Worksheet named 'transaction' not found\n",
            "Please ensure the sheet names in 'tf.xlsx' match the code.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Regression Model ‚Äî Predict Rating\n",
        "\n"
      ],
      "metadata": {
        "id": "pYqI0GzgZ1Ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_encoded = X.copy()\n",
        "for col in ['ContinentId_x', 'RegionId', 'CountryId', 'CityId', 'AttractionTypeId']:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X_encoded[col].astype(str))\n"
      ],
      "metadata": {
        "id": "9mzx4sk_d9pi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "83b8880a-b2f9-44a8-a8a1-48a5eb972d55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d9f94658f34b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ContinentId_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RegionId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CountryId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CityId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AttractionTypeId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg_model = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n"
      ],
      "metadata": {
        "id": "pirdFgc0d9mE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_frac = 0.2  # Use 20% of data for faster iteration\n",
        "X_sample = X_encoded.sample(frac=sample_frac, random_state=42)\n",
        "y_sample = y.loc[X_sample.index]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "-Iwd2jM7d9jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "}\n",
        "\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
        "\n",
        "lgb_model = lgb.train(\n",
        "    params,\n",
        "    lgb_train,\n",
        "    valid_sets=[lgb_train, lgb_eval],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=10)]\n",
        ")\n",
        "\n",
        "y_pred = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)\n"
      ],
      "metadata": {
        "id": "8lvwDuANeWBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model.save_model('lgbm_rating_model.txt')\n",
        "print(\"‚úÖ LightGBM model saved as 'lgbm_rating_model.txt'\")\n"
      ],
      "metadata": {
        "id": "DjsD6H4rekSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"üìà R2 Score:\", round(r2, 3))\n"
      ],
      "metadata": {
        "id": "TgRZmUAlewM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = df[features_reg].copy()\n",
        "\n",
        "# Cyclical encoding for month\n",
        "X['VisitMonth_sin'] = np.sin(2 * np.pi * X['VisitMonth'] / 12)\n",
        "X['VisitMonth_cos'] = np.cos(2 * np.pi * X['VisitMonth'] / 12)\n",
        "\n",
        "# Cyclical encoding for year (assuming VisitYear covers several years)\n",
        "max_year = X['VisitYear'].max()\n",
        "min_year = X['VisitYear'].min()\n",
        "X['VisitYear_sin'] = np.sin(2 * np.pi * (X['VisitYear'] - min_year) / (max_year - min_year))\n",
        "X['VisitYear_cos'] = np.cos(2 * np.pi * (X['VisitYear'] - min_year) / (max_year - min_year))\n",
        "\n",
        "# Drop original VisitMonth and VisitYear if you want\n",
        "X = X.drop(['VisitMonth', 'VisitYear'], axis=1)\n"
      ],
      "metadata": {
        "id": "Ul5mDVS4ey68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for col in ['ContinentId_x', 'RegionId', 'CountryId', 'CityId', 'AttractionTypeId']:\n",
        "    X[col] = X[col].astype(str)  # convert to string just in case\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])\n"
      ],
      "metadata": {
        "id": "MVHdjoTmfEhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "rmses = []\n",
        "r2s = []\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    val_data = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "    params = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "    }\n",
        "\n",
        "   model = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    valid_sets=[train_data, val_data],\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(0)]  # suppress output\n",
        ")\n",
        "\n",
        "    y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    r2 = r2_score(y_val, y_pred)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "\n",
        "print(f\"Average RMSE: {np.mean(rmses):.3f} ¬± {np.std(rmses):.3f}\")\n",
        "print(f\"Average R2 Score: {np.mean(r2s):.3f} ¬± {np.std(r2s):.3f}\")\n"
      ],
      "metadata": {
        "id": "IsXbJ72ifJ7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Prepare features with cyclical encoding\n",
        "X = df[features_reg].copy()\n",
        "\n",
        "# Cyclical encoding for month\n",
        "X['VisitMonth_sin'] = np.sin(2 * np.pi * X['VisitMonth'] / 12)\n",
        "X['VisitMonth_cos'] = np.cos(2 * np.pi * X['VisitMonth'] / 12)\n",
        "\n",
        "# Cyclical encoding for year\n",
        "max_year = X['VisitYear'].max()\n",
        "min_year = X['VisitYear'].min()\n",
        "X['VisitYear_sin'] = np.sin(2 * np.pi * (X['VisitYear'] - min_year) / (max_year - min_year))\n",
        "X['VisitYear_cos'] = np.cos(2 * np.pi * (X['VisitYear'] - min_year) / (max_year - min_year))\n",
        "\n",
        "# Drop original VisitMonth and VisitYear\n",
        "X = X.drop(['VisitMonth', 'VisitYear'], axis=1)\n",
        "\n",
        "# Label encode categorical features\n",
        "for col in ['ContinentId_x', 'RegionId', 'CountryId', 'CityId', 'AttractionTypeId']:\n",
        "    X[col] = X[col].astype(str)\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "\n",
        "y = df[target]\n",
        "\n",
        "# Set up 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "rmses = []\n",
        "r2s = []\n",
        "\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'verbosity': -1,\n",
        "    'boosting_type': 'gbdt',\n",
        "}\n",
        "\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    train_data = lgb.Dataset(X_train, label=y_train)\n",
        "    val_data = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        train_data,\n",
        "        valid_sets=[train_data, val_data],\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(0)]\n",
        "    )\n",
        "\n",
        "    y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    r2 = r2_score(y_val, y_pred)\n",
        "    rmses.append(rmse)\n",
        "    r2s.append(r2)\n",
        "\n",
        "print(f\"Average RMSE: {np.mean(rmses):.3f} ¬± {np.std(rmses):.3f}\")\n",
        "print(f\"Average R2 Score: {np.mean(r2s):.3f} ¬± {np.std(r2s):.3f}\")\n"
      ],
      "metadata": {
        "id": "DZTm0z3KfOp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_BWpP1l1gVOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imbalanced-learn\n"
      ],
      "metadata": {
        "id": "8izUVA4ChG5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost imbalanced-learn scikit-learn\n"
      ],
      "metadata": {
        "id": "PsxA-lE0iPWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade xgboost\n"
      ],
      "metadata": {
        "id": "x_PN_mVMi589"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "print(xgboost.__version__)  # Should print 1.3.0 or higher\n"
      ],
      "metadata": {
        "id": "e2zdkas4jGdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# -----------------------------\n",
        "# Data Preparation\n",
        "# -----------------------------\n",
        "features_clf = [\n",
        "    'VisitYear', 'VisitMonth', 'ContinentId_x', 'RegionId',\n",
        "    'CountryId', 'CityId', 'AttractionTypeId'\n",
        "]\n",
        "target_clf = 'VisitMode'\n",
        "\n",
        "X = df[features_clf].copy()\n",
        "y = df[target_clf]\n",
        "\n",
        "# Cyclical encoding for time-based features\n",
        "X['VisitMonth_sin'] = np.sin(2 * np.pi * X['VisitMonth'] / 12)\n",
        "X['VisitMonth_cos'] = np.cos(2 * np.pi * X['VisitMonth'] / 12)\n",
        "X['VisitYear_sin'] = np.sin(2 * np.pi * (X['VisitYear'] - X['VisitYear'].min()) / (X['VisitYear'].max() - X['VisitYear'].min()))\n",
        "X['VisitYear_cos'] = np.cos(2 * np.pi * (X['VisitYear'] - X['VisitYear'].min()) / (X['VisitYear'].max() - X['VisitYear'].min()))\n",
        "X.drop(['VisitMonth', 'VisitYear'], axis=1, inplace=True)\n",
        "\n",
        "# Label encode categorical features\n",
        "for col in ['ContinentId_x', 'RegionId', 'CountryId', 'CityId', 'AttractionTypeId']:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "\n",
        "# Label encode target\n",
        "y_le = LabelEncoder()\n",
        "y_encoded = y_le.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# Train XGBoost Model\n",
        "# -----------------------------\n",
        "model = XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=len(np.unique(y_encoded)),\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    n_estimators=200,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train with early stopping\n",
        "model.fit(\n",
        "    X_train_res,\n",
        "    y_train_res,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    eval_metric='mlogloss',\n",
        "    early_stopping_rounds=10\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluate the Model\n",
        "# -----------------------------\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"\\n‚úÖ Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[str(cls) for cls in y_le.classes_]))\n"
      ],
      "metadata": {
        "id": "_AKvMOuNjk-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=len(np.unique(y_encoded)),\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    n_estimators=200,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'  # <- here instead of fit()\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train_res,\n",
        "    y_train_res,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    early_stopping_rounds=10\n",
        ")\n"
      ],
      "metadata": {
        "id": "PR7hGqcrjyJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# -----------------------------\n",
        "# Data Preparation\n",
        "# -----------------------------\n",
        "features_clf = [\n",
        "    'VisitYear', 'VisitMonth', 'ContinentId_x', 'RegionId',\n",
        "    'CountryId', 'CityId', 'AttractionTypeId'\n",
        "]\n",
        "target_clf = 'VisitMode'\n",
        "\n",
        "X = df[features_clf].copy()\n",
        "y = df[target_clf]\n",
        "\n",
        "# Cyclical encoding for time-based features\n",
        "X['VisitMonth_sin'] = np.sin(2 * np.pi * X['VisitMonth'] / 12)\n",
        "X['VisitMonth_cos'] = np.cos(2 * np.pi * X['VisitMonth'] / 12)\n",
        "X['VisitYear_sin'] = np.sin(\n",
        "    2 * np.pi * (X['VisitYear'] - X['VisitYear'].min()) /\n",
        "    (X['VisitYear'].max() - X['VisitYear'].min())\n",
        ")\n",
        "X['VisitYear_cos'] = np.cos(\n",
        "    2 * np.pi * (X['VisitYear'] - X['VisitYear'].min()) /\n",
        "    (X['VisitYear'].max() - X['VisitYear'].min())\n",
        ")\n",
        "X.drop(['VisitMonth', 'VisitYear'], axis=1, inplace=True)\n",
        "\n",
        "# Label encode categorical features\n",
        "for col in ['ContinentId_x', 'RegionId', 'CountryId', 'CityId', 'AttractionTypeId']:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
        "\n",
        "# Label encode target\n",
        "y_le = LabelEncoder()\n",
        "y_encoded = y_le.fit_transform(y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Apply SMOTE for class balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# Train XGBoost Model\n",
        "# -----------------------------\n",
        "model = XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    num_class=len(np.unique(y_encoded)),\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    n_estimators=200,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    random_state=42,\n",
        "    eval_metric='mlogloss'  # you can keep this if supported\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train_res,\n",
        "    y_train_res,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    # early_stopping_rounds=10  <-- remove this line\n",
        ")\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"\\n‚úÖ Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=[str(cls) for cls in y_le.classes_]))\n"
      ],
      "metadata": {
        "id": "vEvdcXXfkZ_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation System ‚Äî Collaborative Filtering\n",
        "\n"
      ],
      "metadata": {
        "id": "vcIITG19lw1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall and reinstall numpy and surprise to ensure compatibility\n",
        "!pip uninstall numpy -y\n",
        "!pip uninstall surprise -y\n",
        "!pip install numpy surprise pandas scikit-learn seaborn matplotlib xgboost lightgbm imbalanced-learn"
      ],
      "metadata": {
        "id": "EULfLXVdmbvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy\n",
        "!pip install numpy\n"
      ],
      "metadata": {
        "id": "IB0kDgUsmz_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall scikit-surprise\n",
        "!pip install scikit-surprise\n"
      ],
      "metadata": {
        "id": "G0zQfLo7mz8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall numpy\n",
        "!pip install --upgrade --force-reinstall scikit-surprise\n"
      ],
      "metadata": {
        "id": "vdbJFuJCnSFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install implicit\n"
      ],
      "metadata": {
        "id": "wvZIarStmD_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix\n",
        "import implicit\n",
        "\n",
        "# Assuming df has columns: UserId, AttractionId, Rating\n",
        "# Convert UserId and AttractionId to categorical codes for matrix indexing\n",
        "df['user_idx'] = df['UserId'].astype('category').cat.codes\n",
        "df['item_idx'] = df['AttractionId'].astype('category').cat.codes\n",
        "\n",
        "# Create sparse user-item matrix\n",
        "user_item_matrix = coo_matrix(\n",
        "    (df['Rating'].astype(float), (df['user_idx'], df['item_idx']))\n",
        ")\n",
        "\n",
        "# Initialize the implicit ALS model\n",
        "model = implicit.als.AlternatingLeastSquares(factors=50, regularization=0.1, iterations=20)\n",
        "\n",
        "# Train the model (implicit library expects item-user matrix)\n",
        "model.fit(user_item_matrix.T)\n",
        "\n",
        "# Get recommendations for a user (e.g. user index 0)\n",
        "user_id = 0\n",
        "recommended = model.recommend(user_id, user_item_matrix.tocsr(), N=10)\n",
        "\n",
        "print(\"Top 10 recommended items for user:\", recommended)\n"
      ],
      "metadata": {
        "id": "8BMSViyfpGnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "az2UA9fVpPsK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}